[{"text": "if you are a developer working on the AI field\u00a0\nyou're very familiar with open AI API uh this\u00a0\u00a0 is the way we can interact with ChatGPT via an\u00a0\nAPI programmatically and I would say that most\u00a0\u00a0 uh AI application are really a wrapper on top\u00a0\nof ChatGPT API so in this video we're going to\u00a0\u00a0 see an alternative to that an open source project\u00a0\nthat lets you run your own custom language models\u00a0\u00a0 without losing compatibility with your existing\u00a0\nAPI calls so the first thing we should ask ourself\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "00:00", "start": 0.04, "duration": 33.76}}, {"text": "is why go to the trouble of setting up a local\u00a0\nprivate language model I think there are three\u00a0\u00a0 reasons the first one is cast uh if you have an\u00a0\napplication that's popular and it's using very\u00a0\u00a0 uh heavily the open API the cost can rise very\u00a0\nquickly and there's a point in which it makes\u00a0\u00a0 more sense to rent or buy your own hardware and\u00a0\nrun your own model um so there's a scaling aspect\u00a0\u00a0 to this there's also privacy which is I think the\u00a0\nbiggest reason because there's some use cases in\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "00:33", "start": 33.8, "duration": 32.760000000000005}}, {"text": "which you cannot use close Source models because\u00a0\nthat cannot leave your system and running your own\u00a0\u00a0 language model allows you to keep everything\u00a0\nwithin your data center and the last reason I\u00a0\u00a0 think is because you may want to experiment with\u00a0\nopen source models there are coming everyday new\u00a0\u00a0 models you can find maybe models that suit your\u00a0\nuse case better with less resources so you may\u00a0\u00a0 want to to use one of these models instead of\u00a0\nbeing logged into one of the open AI supported\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "01:06", "start": 66.56, "duration": 32.400000000000006}}, {"text": "models so in a previous video we saw that running\u00a0\na language model is not hard at all if you need a\u00a0\u00a0 help with that be sure to check that video first\u00a0\nand then come back so today we're going to check\u00a0\u00a0 out local AI this is an open source project that\u00a0\naims to be a drop in replacement for open AI it\u00a0\u00a0 has a lot of feature uh you can use it as a chat\u00a0\nmodel you can even use function call calling that\u00a0\u00a0 lets you integrate with other parts of your system\u00a0\nyou have text to speech and AIO to text you can\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "01:38", "start": 98.96, "duration": 31.64}}, {"text": "do image generation you can index documents\u00a0\nuh there's a model Gallery you can pull from\u00a0\u00a0 Hugging face this is the largest repository for\u00a0\nopen source models so you have a lot of choices\u00a0\u00a0 um also you have a vision API and there's a lot\u00a0\nof an ecosystem of mods plugins and if you have\u00a0\u00a0 a GPU you can accelerate your model with GPU\u00a0\nbut you can even run uh these models without\u00a0\u00a0 a GPU so architecture wise uh local AI presents\u00a0\nan OpenAI compatible API you can connect to that\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "02:10", "start": 130.6, "duration": 35.68000000000001}}, {"text": "API or your products or project or application\u00a0\ncan connect to that API behind that there's uh\u00a0\u00a0 the Llama the local OpenAI engine which is written\u00a0\nin Go and it can connect with a lot of different\u00a0\u00a0 models via plugin and extensions so you can you\u00a0\ncan have uh for example an image generator with\u00a0\u00a0 Stable Diffusion you have you can have a Lama\u00a0\nlanguage model so uh you can hit external apis\u00a0\u00a0 also and you can run everything in your command\u00a0\nline or in a container or in kubernetes for for\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "02:46", "start": 166.28, "duration": 34.08000000000001}}, {"text": "additional scale so this is the local AI website\u00a0\nthe first thing we need to go is to go to the\u00a0\u00a0 getting starting section and we have a few options\u00a0\nhere to run if we running on an Intel chip on an\u00a0\u00a0 x86 chip we can directly execute this with Docker\u00a0\nor Docker compose or of course kubernetes these\u00a0\u00a0 are all valid options if you're running on Intel\u00a0\nchips um so the only thing you have to keep in\u00a0\u00a0 mind is that you have to download a model and this\u00a0\nimage weighs around 30 gab so it's a big image so\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "03:20", "start": 200.36, "duration": 37.0}}, {"text": "you have to have a lot of memory and a lot of big\u00a0\nspace but if you are like me and running on Apple\u00a0\u00a0 silicon running using Docker is not the best\u00a0\noption because there's an emulation layer so\u00a0\u00a0 in my case for for an M1 chip I would need to go\u00a0\nto here to build instructions and basically build\u00a0\u00a0 clone and build the the application just keep in\u00a0\nmind there's a few options if you're are going to\u00a0\u00a0 build uh to enable GPU there's also different\u00a0\nversions of the docker image if the depending\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "03:57", "start": 237.36, "duration": 32.56}}, {"text": "if you have a GPU machine or not so you have to\u00a0\npick the right uh Docker image so what I'm going\u00a0\u00a0 to do first is to build local AI in my machine\u00a0\nto test it and then we are going to to do some\u00a0\u00a0 some trials following the instructions from the\u00a0\nwebsite I downloaded and clone the repository I\u00a0\u00a0 built uh the local AI binary and downloaded a\u00a0\ncouple of models uh the this come by default\u00a0\u00a0 this is uh small models that run and GPT4ALL which\u00a0\nis a an open source alternative to GPT4ALL and I\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "04:29", "start": 269.92, "duration": 36.079999999999984}}, {"text": "also downloaded a Llama2 model from Hugging Face\u00a0\nwe are going to test it next so to start the API\u00a0\u00a0 server we're going to call a local AI pass the\u00a0\nmodels P the directory contained in the models\u00a0\u00a0 and after a few seconds we should have uh the\u00a0\nAPI server already there it is so let's open\u00a0\u00a0 a different terminal and test the endpoint with\u00a0\ncurl for example we can call the models endpoint\u00a0\u00a0 and will show us the available models or we can\u00a0\nsimply send a request to the model here we are\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "05:06", "start": 306.0, "duration": 36.80000000000001}}, {"text": "hitting the local endpoint and we are sending the\u00a0\npayload with a message basically saying how are\u00a0\u00a0 you and after a few seconds we have uh the answer\u00a0\nas you can see here we had to specify the model\u00a0\u00a0 this is the the basic model and the answer is here\u00a0\nbasically we are getting a message uh a response\u00a0\u00a0 from the model so this is using the regular open\u00a0\nAPI format and we are not inventing anything new\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "05:42", "start": 342.8, "duration": 30.480000000000018}}, {"text": "here we just using uh a local service instead\u00a0\nof the open AI uh endpoint let's see how is the\u00a0\u00a0 procedure to add a model to local AI let's go to\u00a0\nhacking face um and we're going to go to models\u00a0\u00a0 we're going to filter here for example let's say I\u00a0\nwant Al 2 for example let me filter by format GGUF\u00a0\u00a0 is a good format for downloading this is seems\u00a0\nlike a good example so here we have the model\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "06:13", "start": 373.28, "duration": 31.640000000000043}}, {"text": "card and we can download the file directly from\u00a0\nhere there are different versions depending on\u00a0\u00a0 the quantization of the model we can download the\u00a0\nsimplest the smallest one here and we're going to\u00a0\u00a0 try it with local AI so one once we downloaded the\u00a0\nfile we go to the local AI SL models and we have\u00a0\u00a0 copied I copied the file here and it's a good\u00a0\nidea to create h a second file which is named\u00a0\u00a0 light model but with extension tmpl and we can\u00a0\ntake a look at the existing template files this\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "06:44", "start": 404.92, "duration": 36.15999999999997}}, {"text": "is the one that comes with local Ai and we can\u00a0\nadapt this for example this is what the model we\u00a0\u00a0 receive when boot ups uh like the instruction that\u00a0\nare added before any user interaction so in this\u00a0\u00a0 case for example I I supplied that you are a model\u00a0\nand you're trying to emulate ChatGPT responses so\u00a0\u00a0 we would try to act more like a ChatGPT API but\u00a0\nyou can put anything you want here so we might\u00a0\u00a0 need to restart the the local AI if we added the\u00a0\nmodel so now that it has started uh with the two\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "07:21", "start": 441.08, "duration": 37.68000000000001}}, {"text": "models we we can go here and query the models and\u00a0\nwe should see here that this model is available so\u00a0\u00a0 let's try uh wearing this new model we can see\u00a0\nwe can send a curl request and the difference\u00a0\u00a0 here is that we have put in the model field the\u00a0\nbasically the model file name with extension so\u00a0\u00a0 uh this should create a more complex uh response\u00a0\nbecause it's a larger model here we have the the\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "07:58", "start": 478.76, "duration": 30.120000000000005}}, {"text": "answer um it took a while like 3 minutes to\u00a0\ncomplete it's running on a very very limited\u00a0\u00a0 machine but it works uh it's a relatively big\u00a0\nmodel for for for my machine at least but yeah\u00a0\u00a0 it's quite quite quite funny the response from\u00a0\nthe model here we know that the endpoint Works\u00a0\u00a0 let's try interacting with the local endpoint\u00a0\nusing the open python Library let's create a new\u00a0\u00a0 file so first we import the open AI Library this\u00a0\nis the the one we would normally use to interact\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "08:28", "start": 508.88, "duration": 32.51999999999998}}, {"text": "with open AI then we need to change the base URL\u00a0\nso instead of quering the open a servers we use\u00a0\u00a0 the local server and then we need an API key we\u00a0\ncan put it here or as an environment variable\u00a0\u00a0 but as you can see it's not a valid key but we\u00a0\nneed to put something because otherwise the the\u00a0\u00a0 library will fail with throw an error so we can\u00a0\nput anything here uh it's not a secret it's just\u00a0\u00a0 a and a filler then we're going to complete the\u00a0\ncode we are going to call this model and then\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "09:01", "start": 541.4, "duration": 36.200000000000045}}, {"text": "send a message you know and bring the output so\u00a0\nlet's test it out a few minutes later we have our\u00a0\u00a0 response uh this is a pretty good response for\u00a0\nfrom the model it took like three or 4 minutes\u00a0\u00a0 but remember we are using a laptop as an engine\u00a0\nso um by changing only to this this really this\u00a0\u00a0 uh line of code we made a this simple change\u00a0\nmade our application uh work with the local AI\u00a0\u00a0 so migrating an existing application it's really\u00a0\neasy it's just a matter of changing the base URL\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "09:37", "start": 577.6, "duration": 36.319999999999936}}, {"text": "and testing it out so for my next and last test\u00a0\nI want to run a chatbot UI uh and try to connect\u00a0\u00a0 with local AI this is a project that designed\u00a0\nto work with open AI first so let's see if I can\u00a0\u00a0 make it work with my local server we're going\u00a0\nto start by installing the chat Boo by cloning\u00a0\u00a0 the repository I have cloned the repository and\u00a0\ninstalled the libraries with npm installed now\u00a0\u00a0 I need to export two variables one is the open AI\u00a0\nI key this is the filler app key and then the app\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "10:13", "start": 613.92, "duration": 34.24000000000012}}, {"text": "Host this is we are overriding the default uh host\u00a0\nfor the for the model we are using a local model\u00a0\u00a0 which is already running in a different terminal\u00a0\nso in order to uh provide a compatibility layer\u00a0\u00a0 with open AI we need to start the local AI server\u00a0\nwith an option in this case we need to Define um\u00a0\u00a0 a environment variable called preload models\u00a0\nuh and this variable basically it says that\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "10:48", "start": 648.16, "duration": 30.32000000000005}}, {"text": "the gpt3-turbo model will be replaced with this\u00a0\nURL uh this is the basic model that comes with\u00a0\u00a0 local AI so basically what we go saying to local\u00a0\nAA is we are going to replace uh the GPT3-turbo\u00a0\u00a0 that the UI expects uh with our own model and we\u00a0\ncan have different a list of models here and we\u00a0\u00a0 have we can have as many models as as we want and\u00a0\nuh if we have this variable defined it's going to\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "11:18", "start": 678.48, "duration": 31.479999999999905}}, {"text": "check if the models are installed if they're\u00a0\ninstalled and un cached it will just start and\u00a0\u00a0 if they're missing it will automatically download\u00a0\nthem into the models directory so now the server\u00a0\u00a0 is ready let's start the UI now we can start the\u00a0\ndevelopment server here we are on the UI we have\u00a0\u00a0 only the gpt3 model available this is the only one\u00a0\nwe we enabled in the galleries Let's test it out so it has start uh generating an answer and\u00a0\nthe streaming support works so it works very\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "11:49", "start": 709.96, "duration": 38.60000000000002}}, {"text": "similarly to ChatGPT obviously it's much slower\u00a0\nbut if I had a more powerful machine it would\u00a0\u00a0 work better but this is a client that's designed\u00a0\nspecifically for open Ai and we could using model\u00a0\u00a0 Galleries and by changing the endpoint we could\u00a0\nchange basically and replace open a with our own\u00a0\u00a0 machine and our own language model and that's\u00a0\nall we were able to replace open AI uh with our\u00a0\u00a0 own language Model so whether your hobby to\u00a0\nthings to experiment with open source models\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "12:28", "start": 748.56, "duration": 33.27999999999997}}, {"text": "and you know try uh your code with different\u00a0\nmodels or if you are a developer seeking to\u00a0\u00a0 integrate these Technologies in your projects\u00a0\nif you need a private language model you can\u00a0\u00a0 have that you can have the API you don't need\u00a0\nto rewrite your code you can use your existing\u00a0\u00a0 code and simply change the backend H so local a\u00a0\npresents a very good alternative obviously you\u00a0\u00a0 will need some powerful hard and you need\u00a0\na lot of time to test and maybe find you\u00a0\u00a0", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "13:01", "start": 781.84, "duration": 30.480000000000018}}, {"text": "your models uh but it's a great start thank you\u00a0\nfor watching and don't forget to like share and\u00a0\u00a0 subscribe if you like this video so you don't\u00a0\nmiss the next one if you have any question or\u00a0\u00a0 want to see more content like this leave\u00a0\nme a message below so until next time see you", "type": "youtube_chunk", "timestamp": "2025-04-27T15:07:33.878697", "tool_name": "youtube_tool", "user_query": "https://www.youtube.com/watch?v=Xh57mMlfuMk", "tags": ["youtube", "Xh57mMlfuMk"], "session_id": null, "youtube_metadata": null, "metadata": {"timestamp": "13:32", "start": 812.32, "duration": 19.239999999999895}}]